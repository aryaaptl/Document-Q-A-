{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryaaptl/Document-Q-A-/blob/main/FINAL_AND_WORKING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "!pip install transformers\n",
        "from transformers import pipeline\n",
        "!pip install pytesseract\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "!sudo apt install tesseract-ocr\n",
        "import os\n",
        "import spacy\n",
        "\n",
        "\n",
        "# Add the Tesseract directory to the PATH environment variable\n",
        "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/bin\"\n",
        "\n",
        "# Load spaCy for keyword extraction\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Import other necessary libraries\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs6E2oHh2oCs",
        "outputId": "1426ac85-4778-4457-8249-2b876440773e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (6,031 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 120895 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_text_from_file(file_path):\n",
        "  \"\"\"Extracts text from a file using OpenCV and Tesseract OCR.\"\"\"\n",
        "  if file_path.endswith(\".pdf\"):\n",
        "    # Implement the function to extract text from PDF files if needed\n",
        "    pass\n",
        "  elif file_path.endswith(\".jpg\") or file_path.endswith(\".png\"):\n",
        "    try:\n",
        "      image = cv2.imread(file_path)\n",
        "      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "      text = pytesseract.image_to_string(gray)\n",
        "      return text # Return the extracted text\n",
        "    except cv2.error as e:\n",
        "      print(f\"Error reading image {file_path}: {e}\")\n",
        "  return \"\" # Return an empty string if text extraction fails\n"
      ],
      "metadata": {
        "id": "fabKzyV22sMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_keywords_from_text(text):\n",
        "  \"\"\"Extract keywords from text using spaCy or other NLP methods.\"\"\"\n",
        "  # Here, we use spaCy to extract nouns as keywords, but you can customize this logic.\n",
        "  doc = nlp(text)\n",
        "  keywords = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
        "  return keywords\n"
      ],
      "metadata": {
        "id": "3rkq_EQE2vHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def filter_images_by_keywords(directory_path):\n",
        "  \"\"\"Filter images in a directory based on extracted keywords from their text.\"\"\"\n",
        "  filtered_images = []\n",
        "\n",
        "  for file_path in os.listdir(directory_path):\n",
        "    text = extract_text_from_file(os.path.join(directory_path, file_path))\n",
        "    keywords = extract_keywords_from_text(text)\n",
        "    if keywords:\n",
        "      filtered_images.append((file_path, text, keywords))\n",
        "\n",
        "  return filtered_images\n",
        "\n"
      ],
      "metadata": {
        "id": "QUfybjIr2xvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_relevant_text(question, text):\n",
        "  \"\"\"Extract the most relevant text from 'text' based on 'question'.\"\"\"\n",
        "  # Implement logic to determine and extract the relevant portion of 'text' that answers 'question'.\n",
        "  # Here, we look for lines containing the question keyword and return the first 3 lines.\n",
        "  relevant_lines = []\n",
        "  lines = text.split('\\n')\n",
        "  for i, line in enumerate(lines):\n",
        "    if question.lower() in line.lower():\n",
        "      relevant_lines.append(line)\n",
        "      if len(relevant_lines) >= 3:\n",
        "        break\n",
        "  return '\\n'.join(relevant_lines)\n",
        "\n"
      ],
      "metadata": {
        "id": "R0v55R2P2z7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, filtered_images):\n",
        "  \"\"\"Answer a user's question based on the filtered images and the question's keywords.\"\"\"\n",
        "  answers = []\n",
        "\n",
        "  for image_path, text, keywords in filtered_images:\n",
        "    # Extract relevant text based on the user's question\n",
        "    relevant_text = extract_relevant_text(question, text)\n",
        "\n",
        "    if relevant_text:\n",
        "      answers.append(relevant_text)\n",
        "\n",
        "  return answers\n"
      ],
      "metadata": {
        "id": "ysLxE__824Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "  directory_path = \"/content/drive/MyDrive/DATASET HACKATHON images\"\n",
        "\n",
        "  # Filter images based on extracted keywords\n",
        "  filtered_images = filter_images_by_keywords(directory_path)\n",
        "\n",
        "  if not filtered_images:\n",
        "    print(\"No images found with extracted keywords.\")\n",
        "    return\n",
        "\n",
        "  print(\"Hello! I'm your chatbot. You can ask me questions about the images.\")\n",
        "\n",
        "  while True:\n",
        "    user_query = input(\"Ask a question or type 'exit' to quit: \")\n",
        "    if user_query.lower() == 'exit':\n",
        "      break\n",
        "\n",
        "    answers = answer_question(user_query, filtered_images)\n",
        "\n",
        "    if not answers:\n",
        "      print(\"I couldn't find an answer to your question.\")\n",
        "    else:\n",
        "      for answer in answers:\n",
        "        print(\"Answer:\", answer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLKR6yow22Oc",
        "outputId": "ed0683e4-66d4-4cfe-ce35-9c99438fe3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I'm your chatbot. You can ask me questions about the images.\n",
            "Ask a question or type 'exit' to quit: Letter of Recommendation\n",
            "Answer: LETTER OF RECOMMENDATION\n",
            "Ask a question or type 'exit' to quit: digital circuit\n",
            "Answer: Digital circuit: Circuit in which the signal used can have fixed number of discrete states. It\n",
            "games etc are example of digital circuits.\n",
            "Advantages of digital circuits:\n",
            "Ask a question or type 'exit' to quit: what is digital circuit\n",
            "I couldn't find an answer to your question.\n",
            "Ask a question or type 'exit' to quit: psychology\n",
            "Answer: e Psychology: Psychology is the scientific study of the human mind and behavior. It\n",
            "Ask a question or type 'exit' to quit: exit\n"
          ]
        }
      ]
    }
  ]
}